{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33679,"databundleVersionId":3212216,"sourceType":"competition"},{"sourceId":8616418,"sourceType":"datasetVersion","datasetId":5157187},{"sourceId":8641062,"sourceType":"datasetVersion","datasetId":5175054}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install python-docx\n!pip install albumentations\n!pip install pytorch-lightning\n!pip install timm\n!pip install torchmetrics","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-10T10:16:16.451142Z","iopub.execute_input":"2024-06-10T10:16:16.452535Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: python-docx in /opt/conda/lib/python3.10/site-packages (1.1.2)\nRequirement already satisfied: lxml>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from python-docx) (5.2.2)\nRequirement already satisfied: typing-extensions>=4.9.0 in /opt/conda/lib/python3.10/site-packages (from python-docx) (4.9.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport pandas as pd \nimport json\nimport cv2\nimport seaborn as sns\nfrom skimage import io\nfrom docx import Document ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to read scientific names from a docx file\ndef read_scientific_names(docx_path):\n    doc = Document(docx_path)\n    scientific_names = []\n    for para in doc.paragraphs:\n        scientific_names.append(para.text.strip())\n    return scientific_names\n\n# Read scientific names from the provided docx file\nscientific_names = read_scientific_names(\"/kaggle/input/vietnameseherb/medical plant.docx\")\nscientific_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"TRAIN_DIR = \"../input/herbarium-2022-fgvc9/train_images/\"\nTEST_DIR = \"../input/herbarium-2022-fgvc9/test_images/\"\n\nwith open(\"../input/herbarium-2022-fgvc9/train_metadata.json\") as json_file:\n    train_meta = json.load(json_file)\nwith open(\"../input/herbarium-2022-fgvc9/test_metadata.json\") as json_file:\n    test_meta = json.load(json_file)\n    \nimage_ids = [image[\"image_id\"] for image in train_meta[\"images\"]]\nimage_dirs = [TRAIN_DIR + image[\"file_name\"] for image in train_meta[\"images\"]]\ncategory_ids = [annot[\"category_id\"] for annot in train_meta[\"annotations\"]]\ngenus_ids = [annot[\"genus_id\"] for annot in train_meta[\"annotations\"] ]\ntest_ids = [image[\"image_id\"] for image in test_meta]\ntest_dirs = [TEST_DIR + image[\"file_name\"] for image in test_meta ]\n\ntrain = pd.DataFrame(data =np.array([image_ids , image_dirs, genus_ids, category_ids ]).T, \n                     columns = [\"image_id\", \"directory\",\"genus_id\", \"category\",])\ntest = pd.DataFrame(data =np.array([test_ids  , test_dirs ]).T, \n                    columns = [\"image_id\", \"directory\",])\n\ncategories = pd.DataFrame(train_meta[\"categories\"])\ncategories = categories[categories[\"scientificName\"].isin(scientific_names)]\n\n# Ensure the data types of the columns to be merged match\ntrain[\"category\"] = train[\"category\"].astype(int)\ncategories[\"category_id\"] = categories[\"category_id\"].astype(int)\n# Merge the test data with the filtered categories data\ntrain = train.merge(categories, left_on=\"category\", right_on=\"category_id\", how=\"inner\")\n\n# Merge the test data with the filtered categories data\ntest[\"image_id\"] = test[\"image_id\"].astype(int)\ntest = test.merge(categories, left_on=\"image_id\", right_on=\"category_id\", how=\"inner\")\n\n\n# Save the filtered data to CSV\ntrain.to_csv(\"train.csv\", index=False)\ntest.to_csv(\"test.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('train.csv')\ngenera = pd.DataFrame(train_meta['genera'])\ngenera  = df_train.merge(genera,on='genus_id', how='inner')\ndf_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('test.csv')\ndf_test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['scientificName'].value_counts().head(10).plot(kind='bar')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sample Images","metadata":{}},{"cell_type":"code","source":"from PIL import Image\ndef display_images(scienName):\n    images = df_train.loc[df_train['scientificName'] == scienName]['directory'][:12]\n    i = 1\n    fig = plt.figure(figsize = (10, 10))\n    plt.suptitle(scienName, fontsize = '35')\n    for image in images:\n        ax = fig.add_subplot(3, 4, i)\n        image = Image.open(image).convert('RGB')\n        ax.imshow(image)\n        i+=1\n    fig.tight_layout()\n    plt.show()\n\ndisplay_images('Abutilon indicum (L.) Sweet')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode Class Labels","metadata":{}},{"cell_type":"code","source":"'''from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\nle.fit(df_train['category'])\ndf_train['category'] = le.transform(df_train['category'])\ndf_train.category.nunique()'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"import timm\nimport torch\nimport torch.nn as nn\nimport torch.functional as F\nfrom torchvision import datasets, transforms,models\nfrom torch.utils.data import Dataset,DataLoader\n\nfrom pytorch_lightning import Trainer, seed_everything\nfrom pytorch_lightning import Callback\nfrom pytorch_lightning.loggers import CSVLogger\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nimport torchmetrics\n\n\nimport albumentations as A\nfrom albumentations.core.composition import Compose\nfrom albumentations.pytorch import ToTensorV2\n\nimport pytorch_lightning as pl\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed = 42\n    model_name = 'tf_efficientnetv2_s'\n    pretrained = True\n    img_size = 224\n    num_classes = df_train.category.nunique() \n    lr = 5e-4\n    min_lr = 1e-6\n    t_max = 20\n    num_epochs = 20\n    batch_size = 128\n    accum = 1\n    precision = 16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(CFG.seed)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom Dataset","metadata":{}},{"cell_type":"code","source":"class VietNamHerbariumDataset(Dataset):\n    def __init__(self,data,transform=None):\n        self.annotations = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self,index):\n        \n        img_path = self.annotations.iloc[index,1]\n        image = io.imread(img_path)\n        y_label = torch.tensor(int(self.annotations.iloc[index,3]))\n        \n        if self.transform:\n            image = self.transform(image=np.array(image))\n        \n        return(image,y_label) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Augmentation","metadata":{}},{"cell_type":"code","source":"def Transform(phase: str):\n    if phase == 'train':\n        return Compose([\n            A.RandomResizedCrop(height=CFG.img_size, width=CFG.img_size),\n            A.HorizontalFlip(p=0.5),\n            A.ShiftScaleRotate(p=0.5),\n            A.RandomBrightnessContrast(p=0.5),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        return A.Compose([\n            A.Resize(height=CFG.img_size, width=CFG.img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataloader","metadata":{}},{"cell_type":"code","source":"train_dataset = VietNamHerbariumDataset(df_train,transform=Transform('train'))\nvalid_dataset = VietNamHerbariumDataset(df_train,transform=Transform('valid'))\n\ntrain_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True, num_workers=2, pin_memory=True, drop_last=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transformed Image","metadata":{}},{"cell_type":"code","source":"dataiter = iter(train_loader)\nimages, labels = next(dataiter)\nprint(images['image'][1].shape)\nprint(labels[1].shape)\nplt.imshow(images['image'][3].squeeze().permute(1,2,0), cmap='Greys_r')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class CustomEfficientNet(nn.Module):\n    def __init__(self, model_name='tf_efficientnetv2_s_in21k', pretrained=True):\n        super().__init__()\n        # timm contains collection of pretrained image models like torchvision.models\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        in_features = self.model.get_classifier().in_features\n        self.model.fc = nn.Linear(in_features, CFG.num_classes)\n\n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nimport pytorch_lightning as pl\nimport torch\nimport torch.nn.functional as F\n\nclass LitModel(pl.LightningModule):\n    def __init__(self, model, cfg):\n        super(LitModel, self).__init__()\n        self.model = model\n        self.cfg = cfg\n        self.valid_preds = []\n        self.valid_labels = []\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = F.cross_entropy(outputs, labels)\n        preds = torch.argmax(outputs, dim=1)\n        train_acc = (preds == labels).float().mean()\n        self.log('train_loss', loss, prog_bar=True)\n        self.log('train_acc', train_acc, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        inputs, labels = batch\n        outputs = self(inputs)\n        loss = F.cross_entropy(outputs, labels)\n        preds = torch.argmax(outputs, dim=1)\n        self.valid_preds.extend(preds.cpu().numpy())\n        self.valid_labels.extend(labels.cpu().numpy())\n        val_acc = (preds == labels).float().mean()\n        self.log('valid_loss', loss, prog_bar=True)\n        self.log('valid_acc', val_acc, prog_bar=True)\n        return loss\n\n    def validation_epoch_end(self, outputs):\n        valid_preds = torch.tensor(self.valid_preds)\n        valid_labels = torch.tensor(self.valid_labels)\n        report = classification_report(valid_labels, valid_preds, output_dict=True)\n        for class_idx, metrics in report.items():\n            if isinstance(metrics, dict):\n                self.log(f'class_{class_idx}_precision', metrics['precision'])\n                self.log(f'class_{class_idx}_recall', metrics['recall'])\n                self.log(f'class_{class_idx}_f1', metrics['f1-score'])\n        self.valid_preds = []\n        self.valid_labels = []\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.cfg.lr)\n        return optimizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CustomEfficientNet(model_name=CFG.model_name, pretrained=CFG.pretrained)\nlit_model = LitHerbarium(model)\nlit_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trainer","metadata":{}},{"cell_type":"code","source":"logger = CSVLogger(save_dir='logs/', name=CFG.model_name)\nlogger.log_hyperparams(CFG.__dict__)\ncheckpoint_callback = ModelCheckpoint(monitor='valid_loss',\n                                      save_top_k=1,\n                                      save_last=True,\n                                      save_weights_only=True,\n                                      filename='checkpoint/{epoch:02d}-{valid_loss:.4f}-{valid_f1:.4f}',\n                                      verbose=False,\n                                      mode='min')\n\n# Initialize early stopping callback\nearly_stopping_callback = EarlyStopping(\n    monitor='valid_loss', \n    patience=3, \n    mode='min'\n)\n\n# Initialize the trainer\ntrainer = pl.Trainer(\n    max_epochs=CFG.num_epochs,\n    devices=1,  \n    accelerator='gpu', \n    accumulate_grad_batches=CFG.accum,\n    precision=CFG.precision,\n    callbacks=[checkpoint_callback, early_stopping_callback],\n    enable_checkpointing=True,\n    logger=logger,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(lit_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(lit_model,'best_model.pth')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Metrics","metadata":{}},{"cell_type":"code","source":"metrics = pd.read_csv(f'{trainer.logger.log_dir}/metrics.csv')\n\ntrain_acc = metrics['train_f1'].dropna().reset_index(drop=True)\nvalid_acc = metrics['valid_f1'].dropna().reset_index(drop=True)\n    \nfig = plt.figure(figsize=(7, 6))\n\nplt.plot(train_acc, color=\"r\", label='train/f1')\nplt.plot(valid_acc, color=\"b\", label='valid/f1')\nplt.ylabel('F1', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='lower right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}/f1.png')\n\ntrain_loss = metrics['train_loss'].dropna().reset_index(drop=True)\nvalid_loss = metrics['valid_loss'].dropna().reset_index(drop=True)\n\nfig = plt.figure(figsize=(7, 6))\nplt.plot(train_loss, color=\"r\", label='train/loss')\nplt.plot(valid_loss, color=\"b\", label='valid/loss')\nplt.ylabel('Loss', fontsize=24)\nplt.xlabel('Epoch', fontsize=24)\nplt.legend(loc='upper right', fontsize=18)\nplt.savefig(f'{trainer.logger.log_dir}/loss.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\n\n","metadata":{}},{"cell_type":"code","source":"df_test = pd.read_csv('test.csv')\ndf_test\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VietNamHerbariumTestDataset(Dataset):\n    def __init__(self, data, transform=None):\n        self.annotations = data\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.annotations)\n    \n    def __getitem__(self, index):\n        img_path = self.annotations.iloc[index, 1]\n        image = io.imread(img_path)\n        \n        if self.transform:\n            image = self.transform(image=np.array(image))\n        \n        return image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the trained model\nmodel = torch.load('/kaggle/input/weight/best_model.pth')\nmodel.eval()\n\n# Define the transformation for inference\ndef inference_transform():\n    return A.Compose([\n        A.Resize(height=CFG.img_size, width=CFG.img_size),\n        A.Normalize(),\n        ToTensorV2(),\n    ])\n\n# Function to perform inference on the test dataset\ndef predict_test(model, test_loader):\n    model.eval()\n    predictions = []\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    model.to(device)\n    with torch.no_grad():\n        for images in test_loader:\n            images = images['image'].to(device)  # Send images to the same device as the model\n            outputs = model(images)\n            predicted_classes = torch.argmax(outputs, dim=1)\n            predictions.extend(predicted_classes.cpu().numpy())\n    return predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create Test Dataloader\ntest_dataset = VietNamHerbariumTestDataset(test, transform=inference_transform())\ntest_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the trained model\nmodel = torch.load('/kaggle/input/weight/best_model.pth')\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Perform inference on the test dataset\npredictions = predict_test(model, test_loader)\n\n# Save the predictions to a CSV file\ntest['predicted_category'] = predictions\ntest.to_csv('test_predictions.csv', index=False)\n\nprint(\"Predictions saved to test_predictions.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the first 10 images along with their predicted categories\nplt.figure(figsize=(15, 6))\nfor i in range(10):\n    image_path = test.iloc[i]['directory']  # Assuming 'directory' contains the file path of images\n    predicted_category = test.iloc[i]['predicted_category']\n    \n    # Load and plot the image\n    image = plt.imread(image_path)\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(image)\n    plt.axis('off')\n    plt.title(f'Predicted: {predicted_category}')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}